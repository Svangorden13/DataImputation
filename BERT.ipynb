{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ask/anaconda3/envs/STA208_BERT/bin/python\n",
      "platform: macOS-13.4-arm64-arm-64bit\n",
      "python 3.9.16\n",
      "pandas 1.5.3\n",
      "numpy 1.24.3\n",
      "torch 2.0.1\n",
      "GPU is NOT available\n",
      "MPS is AVAILABLE\n",
      "target device is mps\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, SequentialSampler, RandomSampler\n",
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "#\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from platform import python_version, platform\n",
    "\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertTokenizer,\n",
    "    TFBertForMaskedLM,\n",
    "    BertForMaskedLM,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    " \n",
    "from sys import executable\n",
    "print(executable)\n",
    "print(\"platform: {}\".format(platform())) #Python Platform: macOS-13.3.1-arm64-arm-64bit\n",
    "print('python ' + python_version())\n",
    "print(pd.__name__, pd.__version__)\n",
    "print(np.__name__, np.__version__)\n",
    "print(torch.__name__, torch.__version__)\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = getattr(torch,'has_mps',False)\n",
    "device = \"mps\" if has_mps \\\n",
    "    else \"gpu\" if has_gpu else \"cpu\"\n",
    "\n",
    "print(\"GPU is\", \"AVAILABLE\" if has_gpu else \"NOT available\")#GPU is NOT AVAILABLE\n",
    "print(\"MPS is\", \"AVAILABLE\" if has_mps else \"NOT available\") #MPS is AVAILABLE\n",
    " \n",
    "print(\"target device is {}\".format(device)) #Target device is mps\n",
    "\n",
    "'''\n",
    "Functions, important globals\n",
    "'''\n",
    "MAX_LENGTH = 128 # for sequence length\n",
    "batch_size = 32 # for training\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "token_encoder_fun = lambda row: tokenizer.encode(row,\n",
    "                                                 add_special_tokens=True,\n",
    "                                                 padding=\"max_length\",\n",
    "                                                 #return_tensors='pt',\n",
    "                                                 max_length=MAX_LENGTH,\n",
    "                                                 )\n",
    "\n",
    "class BertHeatFlux(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertHeatFlux, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        # x[1].shape[-1]\n",
    "        self.linear = torch.nn.Linear(768, 1)\n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        output = self.bert(input_ids, attention_masks)\n",
    "        pooled_output = output[1]\n",
    "        dropout = self.dropout(pooled_output)\n",
    "        out = self.linear(dropout)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training/Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          id        author geometry pressure [MPa] mass_flux [kg/m2-s]  \\\n",
       "0         0      Thompson     tube            7.0              3770.0   \n",
       "1         1      Thompson     tube            nan              6049.0   \n",
       "2         2      Thompson      nan          13.79              2034.0   \n",
       "3         3          Beus  annulus          13.79              3679.0   \n",
       "4         5           nan      nan          17.24              3648.0   \n",
       "...     ...           ...      ...            ...                 ...   \n",
       "23089  1861  Richenderfer    plate           1.01              1500.0   \n",
       "23090  1862  Richenderfer    plate           1.01              1500.0   \n",
       "23091  1863  Richenderfer    plate           1.01              2000.0   \n",
       "23092  1864  Richenderfer    plate           1.01              2000.0   \n",
       "23093  1865  Richenderfer    plate           1.01              2000.0   \n",
       "\n",
       "      D_e [mm] D_h [mm] length [mm] chf_exp [MW/m2] x_e_out [-]  \\\n",
       "0          nan     10.8       432.0             3.6      0.1754   \n",
       "1         10.3     10.3       762.0             6.2     -0.0416   \n",
       "2          7.7      7.7       457.0             2.5      0.0335   \n",
       "3          5.6     15.2      2134.0             3.0     -0.0279   \n",
       "4          nan      1.9       696.0             3.6     -0.0711   \n",
       "...        ...      ...         ...             ...         ...   \n",
       "23089     15.0    120.0        10.0             9.4     -0.0218   \n",
       "23090     15.0    120.0        10.0            10.4     -0.0434   \n",
       "23091     15.0    120.0        10.0            10.8     -0.0109   \n",
       "23092     15.0    120.0        10.0            10.9     -0.0218   \n",
       "23093     15.0    120.0        10.0            11.5     -0.0434   \n",
       "\n",
       "                                                sequence  \n",
       "0      author: Thompson geometry: tube pressure [MPa]...  \n",
       "1      author: Thompson geometry: tube pressure [MPa]...  \n",
       "2      author: Thompson geometry: nan pressure [MPa]:...  \n",
       "3      author: Beus geometry: annulus pressure [MPa]:...  \n",
       "4      author: nan geometry: nan pressure [MPa]: 17.2...  \n",
       "...                                                  ...  \n",
       "23089  author: Richenderfer geometry: plate pressure ...  \n",
       "23090  author: Richenderfer geometry: plate pressure ...  \n",
       "23091  author: Richenderfer geometry: plate pressure ...  \n",
       "23092  author: Richenderfer geometry: plate pressure ...  \n",
       "23093  author: Richenderfer geometry: plate pressure ...  \n",
       "\n",
       "[23094 rows x 11 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the numerical data you want to train BERT on\n",
    "df1 = pd.read_csv(\"data.csv\")\n",
    "df2 = pd.read_csv('Data_CHF_Zhao_2020_ATE.csv')\n",
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# Define the name of the column that you want to move to the end of the DataFrame\n",
    "column_name = \"x_e_out [-]\"\n",
    "\n",
    "# Select the column and drop it from the DataFrame\n",
    "column_to_move = df[column_name]\n",
    "col = df.drop(column_name, axis=1, inplace=True)\n",
    "\n",
    "# Append the column back to the end of the DataFrame\n",
    "df[column_name] = column_to_move\n",
    "\n",
    "# select only rows where x_e out exists\n",
    "#data = df[df[\"x_e_out [-]\"].isna()]\n",
    "data = df[~df[\"x_e_out [-]\"].isna()]\n",
    "\n",
    "# start with a small data set for speed\n",
    "#data = data[0:1000]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Convert numerical values to string format to match BERT input requirement\n",
    "data = data.astype(str)\n",
    "\n",
    "data[\"sequence\"] = \"\"\n",
    "\n",
    "# Concatenate all the values in a row into a single string using the column names\n",
    "# Iterate through rows and columns\n",
    "for index, row in data.iterrows():\n",
    "    string = \"\"\n",
    "    for column in data.columns:\n",
    "        if column == \"x_e_out [-]\": \n",
    "            # Do not add mask tokens, simply ignore\n",
    "            #string += column + \": \" + '[MASK]'*4 + \" \"\n",
    "            continue\n",
    "        if column == \"sequence\" or column == 'id':\n",
    "            continue\n",
    "        string += column + \": \" + str(row[column]) + \" \"\n",
    "    masked_string = string.strip()\n",
    "    data[\"sequence\"][index] = masked_string\n",
    "\n",
    "data.describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Optimize \n",
    "BERT Masked LM in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Prepare data as Ax = B\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# A\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sequences \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[39m# B\u001b[39;00m\n\u001b[1;32m      5\u001b[0m x_e_out \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mx_e_out [-]\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare data as Ax = B\n",
    "# A\n",
    "sequences = data[\"sequence\"]\n",
    "# B\n",
    "x_e_out = data['x_e_out [-]']\n",
    "\n",
    "tokenized_data = sequences.apply(token_encoder_fun)\n",
    "tokenized_data = tokenized_data.reset_index(drop=True)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_data)\n",
    "\n",
    "attention_masks = torch.empty( ( len(input_ids), MAX_LENGTH ) )\n",
    "\n",
    "# Generate attention masks\n",
    "for i in trange(len(input_ids)):\n",
    "    tokens = input_ids[i, :]\n",
    "    row_mask = [int(token_id.item() > 0) for token_id in tokens]\n",
    "    row_mask = torch.tensor(row_mask).unsqueeze(0)\n",
    "    attention_masks[i] = row_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e_out = data['x_e_out [-]'].astype(float)\n",
    "x_e_out = torch.tensor(x_e_out, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, x_e_out)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertHeatFlux(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertHeatFlux().to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5b8b7cdbd7485fad33e13d198efa9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29f060b46f44db1a66f17140c80ce7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f95b4a298b40e28f9815fd06d120ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8142e031202e48f497db78b08705be4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823599907fdb4f6a90f9dc2981bf303f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65825edecc764f5b80e34579ff971fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.006\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define the optimizer and loss fn\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Step 4: Train the model\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in trange(num_epochs):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(input_ids, \n",
    "                        attention_mask)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #torch.nn.utils.clip_grad\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss and accuracy of the model for this epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.3f}\")\n",
    "\n",
    "torch.save(model, 'bert_fine-tuned-1.sav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BertHeatFlux Model Names\n",
    "***\n",
    "- `bert_fine-tuned_1.sav`\n",
    "  - epochs=5, training: data.csv + Data_CHF\n",
    "  - loss: 0.014, 0.007, 0.007, 0.003, 0.006\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d5ada9b2864697a32a4c8e93fcd5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 6.045\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "with torch.no_grad(): \n",
    "  mean_squared_error = MeanSquaredError(squared=False).to(device)\n",
    "  RMSE = 0\n",
    "  for batch in test_dataloader:\n",
    "    input_ids, attention_mask, target = [x.to(device) for x in batch]\n",
    "\n",
    "    # Get the logits for the masked tokens\n",
    "    #outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    preds = model(input_ids, \n",
    "                    attention_mask)\n",
    "    \n",
    "    RMSE += mean_squared_error(preds, target)\n",
    "  RMSE = RMSE.cpu().detach().numpy()\n",
    "# Print the accuracy of the model\n",
    "print(\"MSE: {:.3f}\".format(RMSE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trained Model for Prediction on Competition Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uses `data_test`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load, predict, output to file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2865ee9b50d640779e986e7d34cd2210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/415 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the numerical data you want to train BERT on\n",
    "df1 = pd.read_csv(\"data.csv\")\n",
    "#df2 = pd.read_csv('Data_CHF_Zhao_2020_ATE.csv')\n",
    "frames = [df1]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# Define the name of the column that you want to move to the end of the DataFrame\n",
    "column_name = \"x_e_out [-]\"\n",
    "\n",
    "# Select the column and drop it from the DataFrame\n",
    "column_to_move = df[column_name]\n",
    "col = df.drop(column_name, axis=1, inplace=True)\n",
    "\n",
    "# Append the column back to the end of the DataFrame\n",
    "df[column_name] = column_to_move\n",
    "\n",
    "# select only rows where x_e out DOES NOT exist\n",
    "data_test = df[df[\"x_e_out [-]\"].isna()]\n",
    "\n",
    "# start with a small data set for speed\n",
    "#######################################\n",
    "data_test = data_test[10000:]\n",
    "#######################################\n",
    "data_test = data_test.reset_index(drop=True)\n",
    "\n",
    "# Convert numerical values to string format to match BERT input requirement\n",
    "data_test = data_test.astype(str)\n",
    "\n",
    "data_test[\"sequence\"] = \"\"\n",
    "\n",
    "# Concatenate all the values in a row into a single string using the column names\n",
    "# Iterate through rows and columns\n",
    "for index, row in data_test.iterrows():\n",
    "    string = \"\"\n",
    "    for column in data_test.columns:\n",
    "        if column == \"x_e_out [-]\": \n",
    "            continue\n",
    "        if column == \"sequence\" or column == 'id':\n",
    "            continue\n",
    "        string += column + \": \" + str(row[column]) + \" \"\n",
    "    masked_string = string.strip()\n",
    "    data_test[\"sequence\"][index] = masked_string\n",
    "\n",
    "sequences = data_test[\"sequence\"]\n",
    "x_e_out = data_test['x_e_out [-]']\n",
    "x_e_out = data_test['x_e_out [-]'].astype(float)\n",
    "x_e_out = torch.tensor(x_e_out, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "tokenized_data = sequences.apply(token_encoder_fun)\n",
    "tokenized_data = tokenized_data.reset_index(drop=True)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_data)\n",
    "\n",
    "attention_masks = torch.empty( ( len(input_ids), MAX_LENGTH ) )\n",
    "\n",
    "# Generate attention masks\n",
    "for i in range(len(input_ids)):\n",
    "    tokens = input_ids[i, :]\n",
    "    row_mask = [int(token_id.item() > 0) for token_id in tokens]\n",
    "    row_mask = torch.tensor(row_mask).unsqueeze(0)\n",
    "    attention_masks[i] = row_mask\n",
    "\n",
    "eval_dataset = TensorDataset(input_ids, attention_masks) #x_e_out is nan so no point\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    sampler=SequentialSampler(eval_dataset)\n",
    ")\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = torch.load('bert_fine-tuned-1.sav').to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = torch.empty( ( len(input_ids), 1 ) ).to(device)\n",
    "i = 0\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    input_ids, attention_mask = [x.to(device) for x in batch]\n",
    "\n",
    "    # Forward pass\n",
    "    pred = model(input_ids.cpu(), \n",
    "                    attention_mask)\n",
    "    \n",
    "    # Print the loss and accuracy of the model for this epoch\n",
    "    predictions[i] = pred\n",
    "    i += 1\n",
    "\n",
    "#np.savetxt('batch11.txt', predictions.cpu().detach().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine output files into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" filenames = ['batch1.txt', 'batch2.txt', 'batch3.txt', 'batch4.txt','batch5.txt','batch6.txt','batch7.txt',\n",
    "'batch8.txt','batch9.txt','batch10.txt','batch11.txt']\n",
    "with open('combined.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read()) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" #data_test = df[df[\"x_e_out [-]\"].isna()]\n",
    "np.savetxt('ids.txt', data_test['id']) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine two text files into a single csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import csv\n",
    "\n",
    "# read in data from file1.txt\n",
    "with open('ids.txt', 'r') as file1:\n",
    "    data1 = file1.read().splitlines()\n",
    "\n",
    "# read in data from file2.txt\n",
    "with open('combined.txt', 'r') as file2:\n",
    "    data2 = file2.read().splitlines()\n",
    "\n",
    "# combine the two lists\n",
    "data = data1 + data2\n",
    "\n",
    "# write combined data to output.csv\n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ID', 'x_e_out'])  # write column headers\n",
    "    for i in range(len(data)):\n",
    "        if i < len(data1):\n",
    "            writer.writerow([data1[i], data2[i]]) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Console/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import model_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchviz\u001b[39;00m \u001b[39mimport\u001b[39;00m make_dot\n\u001b[1;32m      2\u001b[0m \u001b[39m#device = torch.device('cpu')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#model = torch.load('bert_fine-tuned-1.sav').to(device)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m make_dot(predictions\u001b[39m.\u001b[39mmean(), params\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(model\u001b[39m.\u001b[39mnamed_parameters()), show_attrs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/IPython/core/displayhook.py:268\u001b[0m, in \u001b[0;36mDisplayHook.__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_displayhook()\n\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_output_prompt()\n\u001b[0;32m--> 268\u001b[0m format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_format_data(result)\n\u001b[1;32m    269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_user_ns(result)\n\u001b[1;32m    270\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_exec_result(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/IPython/core/displayhook.py:157\u001b[0m, in \u001b[0;36mDisplayHook.compute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_format_data\u001b[39m(\u001b[39mself\u001b[39m, result):\n\u001b[1;32m    128\u001b[0m     \u001b[39m\"\"\"Compute format data of the object to be displayed.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[39m    The format data is a generalization of the :func:`repr` of an object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49mdisplay_formatter\u001b[39m.\u001b[39;49mformat(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/IPython/core/formatters.py:149\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mipython_display_formatter(obj):\n\u001b[1;32m    146\u001b[0m     \u001b[39m# object handled itself, don't proceed\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m {}, {}\n\u001b[0;32m--> 149\u001b[0m format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmimebundle_formatter(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m format_dict \u001b[39mor\u001b[39;00m md_dict:\n\u001b[1;32m    152\u001b[0m     \u001b[39mif\u001b[39;00m include:\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/IPython/core/formatters.py:974\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    971\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    973\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m         \u001b[39mreturn\u001b[39;00m method(include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/jupyter_integration.py:112\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repr_image_svg_xml\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    111\u001b[0m     \u001b[39m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipe(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msvg\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mSVG_ENCODING)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpipe\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m          \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m          renderer: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m          engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m          encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m     63\u001b[0m     \u001b[39m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m        '<?xml version='\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_legacy(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    105\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    106\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    107\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    108\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    109\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    110\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@_tools\u001b[39m\u001b[39m.\u001b[39mdeprecate_positional_args(supported_number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe_legacy\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    114\u001b[0m                  \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                  engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                  encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_future(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    122\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    123\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    124\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    125\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    126\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    127\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/piping.py:149\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(encoding) \u001b[39mis\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding):\n\u001b[1;32m    148\u001b[0m         \u001b[39m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_lines_string(\u001b[39m*\u001b[39;49margs, encoding\u001b[39m=\u001b[39;49mencoding, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    150\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m         raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_lines(\u001b[39m*\u001b[39margs, input_encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/backend/piping.py:212\u001b[0m, in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    206\u001b[0m cmd \u001b[39m=\u001b[39m dot_command\u001b[39m.\u001b[39mcommand(engine, \u001b[39mformat\u001b[39m,\n\u001b[1;32m    207\u001b[0m                           renderer\u001b[39m=\u001b[39mrenderer,\n\u001b[1;32m    208\u001b[0m                           formatter\u001b[39m=\u001b[39mformatter,\n\u001b[1;32m    209\u001b[0m                           neato_no_op\u001b[39m=\u001b[39mneato_no_op)\n\u001b[1;32m    210\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_lines\u001b[39m\u001b[39m'\u001b[39m: input_lines, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m: encoding}\n\u001b[0;32m--> 212\u001b[0m proc \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mrun_check(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, quiet\u001b[39m=\u001b[39;49mquiet, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m proc\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/backend/execute.py:79\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mcapture_output\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     78\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPIPE\n\u001b[0;32m---> 79\u001b[0m     proc \u001b[39m=\u001b[39m _run_input_lines(cmd, input_lines, kwargs\u001b[39m=\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     proc \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mrun(cmd, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/graphviz/backend/execute.py:105\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m input_lines:\n\u001b[1;32m    103\u001b[0m     stdin_write(line)\n\u001b[0;32m--> 105\u001b[0m stdout, stderr \u001b[39m=\u001b[39m popen\u001b[39m.\u001b[39;49mcommunicate()\n\u001b[1;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m subprocess\u001b[39m.\u001b[39mCompletedProcess(popen\u001b[39m.\u001b[39margs, popen\u001b[39m.\u001b[39mreturncode,\n\u001b[1;32m    107\u001b[0m                                    stdout\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/subprocess.py:1134\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[1;32m   1135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/subprocess.py:1979\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   1973\u001b[0m                         stdout, stderr,\n\u001b[1;32m   1974\u001b[0m                         skip_check_and_raise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1975\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(  \u001b[39m# Impossible :)\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1977\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfailed to raise TimeoutExpired.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1979\u001b[0m ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m   1980\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   1982\u001b[0m \u001b[39m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   1983\u001b[0m \u001b[39m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "#device = torch.device('cpu')\n",
    "#model = torch.load('bert_fine-tuned-1.sav').to(device)\n",
    "\n",
    "make_dot(predictions.mean(), params=dict(model.named_parameters()), show_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m input_ids \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m input_ids[\u001b[39m0\u001b[39m]] \n\u001b[1;32m     14\u001b[0m tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(input_ids)  \u001b[39m# Convert input ids to token strings\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model_view(attention, tokens)\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/bertviz/model_view.py:62\u001b[0m, in \u001b[0;36mmodel_view\u001b[0;34m(attention, tokens, sentence_b_start, prettify_tokens, display_mode, encoder_attention, decoder_attention, cross_attention, encoder_tokens, decoder_tokens, include_layers, include_heads, html_action)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m encoder_attention \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m decoder_attention \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m cross_attention \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \\\n\u001b[1;32m     59\u001b[0m         \u001b[39mor\u001b[39;00m encoder_tokens \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m decoder_tokens \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf you specify \u001b[39m\u001b[39m'\u001b[39m\u001b[39mattention\u001b[39m\u001b[39m'\u001b[39m\u001b[39m you may not specify any encoder-decoder arguments. This\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m argument is only for self-attention models.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m n_heads \u001b[39m=\u001b[39m num_heads(attention)\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m include_layers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     include_layers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(num_layers(attention)))\n",
      "File \u001b[0;32m~/anaconda3/envs/STA208_BERT/lib/python3.9/site-packages/bertviz/util.py:26\u001b[0m, in \u001b[0;36mnum_heads\u001b[0;34m(attention)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_heads\u001b[39m(attention):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m attention[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "\"\"\" device = torch.device('cpu')\n",
    "model = torch.load('bert_fine-tuned-1.sav').to(device)\n",
    "model.eval()\n",
    "\n",
    "inp = eval_dataset[-1]\n",
    "input_ids, attention_mask = [x.view(1,128) for x in inp]\n",
    "\n",
    "    # Forward pass\n",
    "outputs = model(input_ids, attention_mask)\n",
    "\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "input_ids = input_ids.tolist()\n",
    "input_ids = [i for i in input_ids[0]] \n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)  # Convert input ids to token strings\n",
    "model_view(attention, tokens)  # Display model view\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertHeatFlux(\n",
    "  (bert): BertModel(\n",
    "    (embeddings): BertEmbeddings(\n",
    "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "      (position_embeddings): Embedding(512, 768)\n",
    "      (token_type_embeddings): Embedding(2, 768)\n",
    "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "      (dropout): Dropout(p=0.1, inplace=False)\n",
    "    )\n",
    "    (encoder): BertEncoder(\n",
    "      (layer): ModuleList(\n",
    "        (0-11): 12 x BertLayer(\n",
    "          (attention): BertAttention(\n",
    "            (self): BertSelfAttention(\n",
    "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "              (dropout): Dropout(p=0.1, inplace=False)\n",
    "            )\n",
    "            (output): BertSelfOutput(\n",
    "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "              (dropout): Dropout(p=0.1, inplace=False)\n",
    "            )\n",
    "          )\n",
    "          (intermediate): BertIntermediate(\n",
    "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "            (intermediate_act_fn): GELUActivation()\n",
    "          )\n",
    "          (output): BertOutput(\n",
    "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "            (dropout): Dropout(p=0.1, inplace=False)\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (pooler): BertPooler(\n",
    "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "      (activation): Tanh()\n",
    "    )\n",
    "  )\n",
    "  (dropout): Dropout(p=0.3, inplace=False)\n",
    "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of BertHeatFlux(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
